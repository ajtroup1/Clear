# 01.clr
Welcome to Clear

*This file is a log of all activity that occured during the interpretation of your source code.*

## Lexical Analysis / Lexing / Tokenization
Lexing (or tokenization) is the process of converting a sequence of characters into a sequence of tokens.

These tokens are the simplest level of strutured data pertaining to the source code information.

*Example Token*: `let` (Type: LET, Literal: 'let')

- Optionally, the token can track other information such as line and column information, which is used for error reporting.

	- Token: `return` (Type: RETURN, Literal:'return', Line: 6, Column: 12)

The lexer reads the source code character by character and generates tokens based on the characters it reads. The lexer is also the first step in the compilation or interpretation process. The lexer is additionally responsible for removing whitespace and comments from the source code.

**Source code:** 
```js
mod file: *;
mod strings: [ concat ];
mod io: [ println ]

let path = "./test.clr";
file.create(path);
file.write(path, "myString");

let renamedPath = "./test2.clr";

file.rename(path, renamedPath);

file.write(renamedPath, "\n\nThis is a new string");

io.println(file.isdir(renamedPath));
io.println(file.isfile(renamedPath));

io.println(file.exists(renamedPath));
io.println(file.exists("../thisdoesnotexits"))

return "Project written to "+strings.concat("'", path, "'");
```

Initializing lexer...

**Lexing source code...**

### Live encounters:

1. Discerned that 'mod' is a keyword 'MOD'
1. Tokenized Token::MOD 'mod' at [line: 1, col: 1]
1. Tokenized Token::IDENT 'file' at [line: 1, col: 5]
1. Tokenized Token::: ':' at [line: 1, col: 9]
1. Tokenized Token::* '*' at [line: 1, col: 11]
1. Tokenized Token::; ';' at [line: 1, col: 12]
1. Encountered newline at [line: 1, col: 13]
1. Discerned that 'mod' is a keyword 'MOD'
1. Tokenized Token::MOD 'mod' at [line: 2, col: 1]
1. Tokenized Token::IDENT 'strings' at [line: 2, col: 5]
1. Tokenized Token::: ':' at [line: 2, col: 12]
1. Tokenized Token::[ '[' at [line: 2, col: 14]
1. Tokenized Token::IDENT 'concat' at [line: 2, col: 16]
1. Tokenized Token::] ']' at [line: 2, col: 23]
1. Tokenized Token::; ';' at [line: 2, col: 24]
1. Encountered newline at [line: 2, col: 25]
1. Discerned that 'mod' is a keyword 'MOD'
1. Tokenized Token::MOD 'mod' at [line: 3, col: 1]
1. Tokenized Token::IDENT 'io' at [line: 3, col: 5]
1. Tokenized Token::: ':' at [line: 3, col: 7]
1. Tokenized Token::[ '[' at [line: 3, col: 9]
1. Tokenized Token::IDENT 'println' at [line: 3, col: 11]
1. Tokenized Token::] ']' at [line: 3, col: 19]
1. Encountered newline at [line: 3, col: 20]
1. Encountered newline at [line: 4, col: 1]
1. Discerned that 'let' is a keyword 'LET'
1. Tokenized Token::LET 'let' at [line: 5, col: 1]
1. Tokenized Token::IDENT 'path' at [line: 5, col: 5]
1. Tokenized Token::= '=' at [line: 5, col: 10]
1. Tokenized Token::STRING './test.clr' at [line: 0, col: 0]
1. Tokenized Token::; ';' at [line: 5, col: 24]
1. Encountered newline at [line: 5, col: 25]
1. Tokenized Token::IDENT 'file' at [line: 6, col: 1]
1. Tokenized Token::. '.' at [line: 6, col: 5]
1. Tokenized Token::IDENT 'create' at [line: 6, col: 6]
1. Tokenized Token::( '(' at [line: 6, col: 12]
1. Tokenized Token::IDENT 'path' at [line: 6, col: 13]
1. Tokenized Token::) ')' at [line: 6, col: 17]
1. Tokenized Token::; ';' at [line: 6, col: 18]
1. Encountered newline at [line: 6, col: 19]
1. Tokenized Token::IDENT 'file' at [line: 7, col: 1]
1. Tokenized Token::. '.' at [line: 7, col: 5]
1. Tokenized Token::IDENT 'write' at [line: 7, col: 6]
1. Tokenized Token::( '(' at [line: 7, col: 11]
1. Tokenized Token::IDENT 'path' at [line: 7, col: 12]
1. Tokenized Token::, ',' at [line: 7, col: 16]
1. Tokenized Token::STRING 'myString' at [line: 0, col: 0]
1. Tokenized Token::) ')' at [line: 7, col: 28]
1. Tokenized Token::; ';' at [line: 7, col: 29]
1. Encountered newline at [line: 7, col: 30]
1. Encountered newline at [line: 8, col: 1]
1. Discerned that 'let' is a keyword 'LET'
1. Tokenized Token::LET 'let' at [line: 9, col: 1]
1. Tokenized Token::IDENT 'renamedPath' at [line: 9, col: 5]
1. Tokenized Token::= '=' at [line: 9, col: 17]
1. Tokenized Token::STRING './test2.clr' at [line: 0, col: 0]
1. Tokenized Token::; ';' at [line: 9, col: 32]
1. Encountered newline at [line: 9, col: 33]
1. Encountered newline at [line: 10, col: 1]
1. Tokenized Token::IDENT 'file' at [line: 11, col: 1]
1. Tokenized Token::. '.' at [line: 11, col: 5]
1. Tokenized Token::IDENT 'rename' at [line: 11, col: 6]
1. Tokenized Token::( '(' at [line: 11, col: 12]
1. Tokenized Token::IDENT 'path' at [line: 11, col: 13]
1. Tokenized Token::, ',' at [line: 11, col: 17]
1. Tokenized Token::IDENT 'renamedPath' at [line: 11, col: 19]
1. Tokenized Token::) ')' at [line: 11, col: 30]
1. Tokenized Token::; ';' at [line: 11, col: 31]
1. Encountered newline at [line: 11, col: 32]
1. Encountered newline at [line: 12, col: 1]
1. Tokenized Token::IDENT 'file' at [line: 13, col: 1]
1. Tokenized Token::. '.' at [line: 13, col: 5]
1. Tokenized Token::IDENT 'write' at [line: 13, col: 6]
1. Tokenized Token::( '(' at [line: 13, col: 11]
1. Tokenized Token::IDENT 'renamedPath' at [line: 13, col: 12]
1. Tokenized Token::, ',' at [line: 13, col: 23]
1. Tokenized Token::STRING '\n\nThis is a new string' at [line: 0, col: 0]
1. Tokenized Token::) ')' at [line: 13, col: 51]
1. Tokenized Token::; ';' at [line: 13, col: 52]
1. Encountered newline at [line: 13, col: 53]
1. Encountered newline at [line: 14, col: 1]
1. Tokenized Token::IDENT 'io' at [line: 15, col: 1]
1. Tokenized Token::. '.' at [line: 15, col: 3]
1. Tokenized Token::IDENT 'println' at [line: 15, col: 4]
1. Tokenized Token::( '(' at [line: 15, col: 11]
1. Tokenized Token::IDENT 'file' at [line: 15, col: 12]
1. Tokenized Token::. '.' at [line: 15, col: 16]
1. Tokenized Token::IDENT 'isdir' at [line: 15, col: 17]
1. Tokenized Token::( '(' at [line: 15, col: 22]
1. Tokenized Token::IDENT 'renamedPath' at [line: 15, col: 23]
1. Tokenized Token::) ')' at [line: 15, col: 34]
1. Tokenized Token::) ')' at [line: 15, col: 35]
1. Tokenized Token::; ';' at [line: 15, col: 36]
1. Encountered newline at [line: 15, col: 37]
1. Tokenized Token::IDENT 'io' at [line: 16, col: 1]
1. Tokenized Token::. '.' at [line: 16, col: 3]
1. Tokenized Token::IDENT 'println' at [line: 16, col: 4]
1. Tokenized Token::( '(' at [line: 16, col: 11]
1. Tokenized Token::IDENT 'file' at [line: 16, col: 12]
1. Tokenized Token::. '.' at [line: 16, col: 16]
1. Tokenized Token::IDENT 'isfile' at [line: 16, col: 17]
1. Tokenized Token::( '(' at [line: 16, col: 23]
1. Tokenized Token::IDENT 'renamedPath' at [line: 16, col: 24]
1. Tokenized Token::) ')' at [line: 16, col: 35]
1. Tokenized Token::) ')' at [line: 16, col: 36]
1. Tokenized Token::; ';' at [line: 16, col: 37]
1. Encountered newline at [line: 16, col: 38]
1. Encountered newline at [line: 17, col: 1]
1. Tokenized Token::IDENT 'io' at [line: 18, col: 1]
1. Tokenized Token::. '.' at [line: 18, col: 3]
1. Tokenized Token::IDENT 'println' at [line: 18, col: 4]
1. Tokenized Token::( '(' at [line: 18, col: 11]
1. Tokenized Token::IDENT 'file' at [line: 18, col: 12]
1. Tokenized Token::. '.' at [line: 18, col: 16]
1. Tokenized Token::IDENT 'exists' at [line: 18, col: 17]
1. Tokenized Token::( '(' at [line: 18, col: 23]
1. Tokenized Token::IDENT 'renamedPath' at [line: 18, col: 24]
1. Tokenized Token::) ')' at [line: 18, col: 35]
1. Tokenized Token::) ')' at [line: 18, col: 36]
1. Tokenized Token::; ';' at [line: 18, col: 37]
1. Encountered newline at [line: 18, col: 38]
1. Tokenized Token::IDENT 'io' at [line: 19, col: 1]
1. Tokenized Token::. '.' at [line: 19, col: 3]
1. Tokenized Token::IDENT 'println' at [line: 19, col: 4]
1. Tokenized Token::( '(' at [line: 19, col: 11]
1. Tokenized Token::IDENT 'file' at [line: 19, col: 12]
1. Tokenized Token::. '.' at [line: 19, col: 16]
1. Tokenized Token::IDENT 'exists' at [line: 19, col: 17]
1. Tokenized Token::( '(' at [line: 19, col: 23]
1. Tokenized Token::STRING '../thisdoesnotexits' at [line: 0, col: 0]
1. Tokenized Token::) ')' at [line: 19, col: 45]
1. Tokenized Token::) ')' at [line: 19, col: 46]
1. Encountered newline at [line: 19, col: 47]
1. Encountered newline at [line: 20, col: 1]
1. Discerned that 'return' is a keyword 'RETURN'
1. Tokenized Token::RETURN 'return' at [line: 21, col: 1]
1. Tokenized Token::STRING 'Project written to ' at [line: 0, col: 0]
1. Tokenized Token::+ '+' at [line: 21, col: 29]
1. Tokenized Token::IDENT 'strings' at [line: 21, col: 30]
1. Tokenized Token::. '.' at [line: 21, col: 37]
1. Tokenized Token::IDENT 'concat' at [line: 21, col: 38]
1. Tokenized Token::( '(' at [line: 21, col: 44]
1. Tokenized Token::STRING ''' at [line: 0, col: 0]
1. Tokenized Token::, ',' at [line: 21, col: 48]
1. Tokenized Token::IDENT 'path' at [line: 21, col: 50]
1. Tokenized Token::, ',' at [line: 21, col: 54]
1. Tokenized Token::STRING ''' at [line: 0, col: 0]
1. Tokenized Token::) ')' at [line: 21, col: 59]
1. Tokenized Token::; ';' at [line: 21, col: 60]
1. Tokenized Token::EOF '' at [line: 0, col: 0]
1. Tokenized Token::EOF '' at [line: 0, col: 0]


**Here is the stream of all tokens generated by the lexer:**

```
- Token::STRING ''' at [line: 0, col: 0]
- Token::STRING 'myString' at [line: 0, col: 0]
- Token::STRING './test2.clr' at [line: 0, col: 0]
- Token::STRING '\n\nThis is a new string' at [line: 0, col: 0]
- Token::STRING '../thisdoesnotexits' at [line: 0, col: 0]
- Token::STRING './test.clr' at [line: 0, col: 0]
- Token::EOF '' at [line: 0, col: 0]
- Token::EOF '' at [line: 0, col: 0]
- Token::STRING ''' at [line: 0, col: 0]
- Token::STRING 'Project written to ' at [line: 0, col: 0]
- Token::MOD 'mod' at [line: 1, col: 1]
- Token::IDENT 'file' at [line: 1, col: 5]
- Token::: ':' at [line: 1, col: 9]
- Token::* '*' at [line: 1, col: 11]
- Token::; ';' at [line: 1, col: 12]
- Token::MOD 'mod' at [line: 2, col: 1]
- Token::IDENT 'strings' at [line: 2, col: 5]
- Token::: ':' at [line: 2, col: 12]
- Token::[ '[' at [line: 2, col: 14]
- Token::IDENT 'concat' at [line: 2, col: 16]
- Token::] ']' at [line: 2, col: 23]
- Token::; ';' at [line: 2, col: 24]
- Token::MOD 'mod' at [line: 3, col: 1]
- Token::IDENT 'io' at [line: 3, col: 5]
- Token::: ':' at [line: 3, col: 7]
- Token::[ '[' at [line: 3, col: 9]
- Token::IDENT 'println' at [line: 3, col: 11]
- Token::] ']' at [line: 3, col: 19]
- Token::LET 'let' at [line: 5, col: 1]
- Token::IDENT 'path' at [line: 5, col: 5]
- Token::= '=' at [line: 5, col: 10]
- Token::; ';' at [line: 5, col: 24]
- Token::IDENT 'file' at [line: 6, col: 1]
- Token::. '.' at [line: 6, col: 5]
- Token::IDENT 'create' at [line: 6, col: 6]
- Token::( '(' at [line: 6, col: 12]
- Token::IDENT 'path' at [line: 6, col: 13]
- Token::) ')' at [line: 6, col: 17]
- Token::; ';' at [line: 6, col: 18]
- Token::IDENT 'file' at [line: 7, col: 1]
- Token::. '.' at [line: 7, col: 5]
- Token::IDENT 'write' at [line: 7, col: 6]
- Token::( '(' at [line: 7, col: 11]
- Token::IDENT 'path' at [line: 7, col: 12]
- Token::, ',' at [line: 7, col: 16]
- Token::) ')' at [line: 7, col: 28]
- Token::; ';' at [line: 7, col: 29]
- Token::LET 'let' at [line: 9, col: 1]
- Token::IDENT 'renamedPath' at [line: 9, col: 5]
- Token::= '=' at [line: 9, col: 17]
- Token::; ';' at [line: 9, col: 32]
- Token::IDENT 'file' at [line: 11, col: 1]
- Token::. '.' at [line: 11, col: 5]
- Token::IDENT 'rename' at [line: 11, col: 6]
- Token::( '(' at [line: 11, col: 12]
- Token::IDENT 'path' at [line: 11, col: 13]
- Token::, ',' at [line: 11, col: 17]
- Token::IDENT 'renamedPath' at [line: 11, col: 19]
- Token::) ')' at [line: 11, col: 30]
- Token::; ';' at [line: 11, col: 31]
- Token::IDENT 'file' at [line: 13, col: 1]
- Token::. '.' at [line: 13, col: 5]
- Token::IDENT 'write' at [line: 13, col: 6]
- Token::( '(' at [line: 13, col: 11]
- Token::IDENT 'renamedPath' at [line: 13, col: 12]
- Token::, ',' at [line: 13, col: 23]
- Token::) ')' at [line: 13, col: 51]
- Token::; ';' at [line: 13, col: 52]
- Token::IDENT 'io' at [line: 15, col: 1]
- Token::. '.' at [line: 15, col: 3]
- Token::IDENT 'println' at [line: 15, col: 4]
- Token::( '(' at [line: 15, col: 11]
- Token::IDENT 'file' at [line: 15, col: 12]
- Token::. '.' at [line: 15, col: 16]
- Token::IDENT 'isdir' at [line: 15, col: 17]
- Token::( '(' at [line: 15, col: 22]
- Token::IDENT 'renamedPath' at [line: 15, col: 23]
- Token::) ')' at [line: 15, col: 34]
- Token::) ')' at [line: 15, col: 35]
- Token::; ';' at [line: 15, col: 36]
- Token::IDENT 'io' at [line: 16, col: 1]
- Token::. '.' at [line: 16, col: 3]
- Token::IDENT 'println' at [line: 16, col: 4]
- Token::( '(' at [line: 16, col: 11]
- Token::IDENT 'file' at [line: 16, col: 12]
- Token::. '.' at [line: 16, col: 16]
- Token::IDENT 'isfile' at [line: 16, col: 17]
- Token::( '(' at [line: 16, col: 23]
- Token::IDENT 'renamedPath' at [line: 16, col: 24]
- Token::) ')' at [line: 16, col: 35]
- Token::) ')' at [line: 16, col: 36]
- Token::; ';' at [line: 16, col: 37]
- Token::IDENT 'io' at [line: 18, col: 1]
- Token::. '.' at [line: 18, col: 3]
- Token::IDENT 'println' at [line: 18, col: 4]
- Token::( '(' at [line: 18, col: 11]
- Token::IDENT 'file' at [line: 18, col: 12]
- Token::. '.' at [line: 18, col: 16]
- Token::IDENT 'exists' at [line: 18, col: 17]
- Token::( '(' at [line: 18, col: 23]
- Token::IDENT 'renamedPath' at [line: 18, col: 24]
- Token::) ')' at [line: 18, col: 35]
- Token::) ')' at [line: 18, col: 36]
- Token::; ';' at [line: 18, col: 37]
- Token::IDENT 'io' at [line: 19, col: 1]
- Token::. '.' at [line: 19, col: 3]
- Token::IDENT 'println' at [line: 19, col: 4]
- Token::( '(' at [line: 19, col: 11]
- Token::IDENT 'file' at [line: 19, col: 12]
- Token::. '.' at [line: 19, col: 16]
- Token::IDENT 'exists' at [line: 19, col: 17]
- Token::( '(' at [line: 19, col: 23]
- Token::) ')' at [line: 19, col: 45]
- Token::) ')' at [line: 19, col: 46]
- Token::RETURN 'return' at [line: 21, col: 1]
- Token::+ '+' at [line: 21, col: 29]
- Token::IDENT 'strings' at [line: 21, col: 30]
- Token::. '.' at [line: 21, col: 37]
- Token::IDENT 'concat' at [line: 21, col: 38]
- Token::( '(' at [line: 21, col: 44]
- Token::, ',' at [line: 21, col: 48]
- Token::IDENT 'path' at [line: 21, col: 50]
- Token::, ',' at [line: 21, col: 54]
- Token::) ')' at [line: 21, col: 59]
- Token::; ';' at [line: 21, col: 60]
```
## Parsing
Parsing is the organization of our tokens into a tree structure that represents the program. This is done by reading the tokens from the lexer sequentially and forming 'nodes' on the fly.

- Nodes are the building blocks of any AST and can range from:
	- LetStatement{ Token: Let, Name: 'x', Value: 5 }
	- Integer{ Token: INT, Value: 0 }
	- InfixExpression{ Token: +, Left: 'x', Operator: '+', Right: '5' }
	

So, essentially these nodes are the next level of abstraction from tokens and represent the structure of the program in a more complex and well-structured manner that is easy to evaluate later.



### Live Encounters:

1. Starting to parse the program node...

	- This requires invoking a loop until end of file is reached, and parsing statements one-by-one until that point. As statements are parsed, they are appended to the `Program`'s `Statements` slice

2. Encountered a `MOD` token, calling `parseModStatement()`...
2. Steps in parsing module / import statement:

	a. Assigning token to the statement to track positioning [line: 1, col: 1]

	b. Assigning module name `file` to the import statement

	c. Encountered a `*` token, signifying this is a wildcard import. Wilcard import simply means **import all** functionality from that module with no need to specify individual functions from the module. Since this is a wildcard import, that also means we have all the information we need, since the module identifier and the fact that we a targeting everything within it is enough to continue.
2. Successfully parsed module statement
	- Module name: `file`
	- Imports: ALL ('*')
2. Parsed a statement to append to program's `Statements` slice: `mod file *;`
2. Encountered a `MOD` token, calling `parseModStatement()`...
2. Steps in parsing module / import statement:

	a. Assigning token to the statement to track positioning [line: 2, col: 1]

	b. Assigning module name `strings` to the import statement

	c. **No wildcard import found**, so we're expecting an array of comma-delimited imports

	d. Invoking a loop to continue parsing import identifiers until a `]` token is reached, which signifies the end of the import list.

	d.2. Parsing import identifier `1`

	- Encountered valid identifier, appending to the list: `1: strings.concat`
2. Successfully parsed module statement
	- Module name: `strings`
	- Imports:
		- `concat`
2. Parsed a statement to append to program's `Statements` slice: `mod strings concat;`
2. Encountered a `MOD` token, calling `parseModStatement()`...
2. Steps in parsing module / import statement:

	a. Assigning token to the statement to track positioning [line: 3, col: 1]

	b. Assigning module name `io` to the import statement

	c. **No wildcard import found**, so we're expecting an array of comma-delimited imports

	d. Invoking a loop to continue parsing import identifiers until a `]` token is reached, which signifies the end of the import list.

	d.2. Parsing import identifier `1`

	- Encountered valid identifier, appending to the list: `1: io.println`
2. Successfully parsed module statement
	- Module name: `io`
	- Imports:
		- `println`
2. Parsed a statement to append to program's `Statements` slice: `mod io println;`
2. Encountered a `LET` token, calling `parseLetStatement()`...
2. Steps in parsing let statement:

	a. Assigning token to the statement to track positioning [line: 5, col: 1]

	b. Assigning valid identifier `path` to the let statement

	c. Parsing the expression to assign to the let statement...

	d. Successfully parsed a valid expression to assign to the let statement: `./test.clr`

	e. Successfully parsed the entire let statement: `let path = ./test.clr;`
2. Parsed a statement to append to program's `Statements` slice: `let path = ./test.clr;`
2. Encountered token (`file`, type 'IDENT') that doesn't have a predefined statement parse function, so it's either an expression or an assignment statement
2. Did not encounter an assign (`=`) token, so this is an expression statement
2. Steps in parsing expression statement:

	a. Assigning token to the statement to track positioning [line: 6, col: 6]

	b. Parsing expression statements is extremely simple. Just parse the expression and wrap it within a Statement implementation...

	c. Successfully parsed the expression statement: `create(path)`

	d. Successfully parsed the entire expression statement: `create(path)`
2. Parsed a statement to append to program's `Statements` slice: `create(path)`
2. Encountered token (`file`, type 'IDENT') that doesn't have a predefined statement parse function, so it's either an expression or an assignment statement
2. Did not encounter an assign (`=`) token, so this is an expression statement
2. Steps in parsing expression statement:

	a. Assigning token to the statement to track positioning [line: 7, col: 6]

	b. Parsing expression statements is extremely simple. Just parse the expression and wrap it within a Statement implementation...

	c. Successfully parsed the expression statement: `write(path, myString)`

	d. Successfully parsed the entire expression statement: `write(path, myString)`
2. Parsed a statement to append to program's `Statements` slice: `write(path, myString)`
2. Encountered a `LET` token, calling `parseLetStatement()`...
2. Steps in parsing let statement:

	a. Assigning token to the statement to track positioning [line: 9, col: 1]

	b. Assigning valid identifier `renamedPath` to the let statement

	c. Parsing the expression to assign to the let statement...

	d. Successfully parsed a valid expression to assign to the let statement: `./test2.clr`

	e. Successfully parsed the entire let statement: `let renamedPath = ./test2.clr;`
2. Parsed a statement to append to program's `Statements` slice: `let renamedPath = ./test2.clr;`
2. Encountered token (`file`, type 'IDENT') that doesn't have a predefined statement parse function, so it's either an expression or an assignment statement
2. Did not encounter an assign (`=`) token, so this is an expression statement
2. Steps in parsing expression statement:

	a. Assigning token to the statement to track positioning [line: 11, col: 6]

	b. Parsing expression statements is extremely simple. Just parse the expression and wrap it within a Statement implementation...

	c. Successfully parsed the expression statement: `rename(path, renamedPath)`

	d. Successfully parsed the entire expression statement: `rename(path, renamedPath)`
2. Parsed a statement to append to program's `Statements` slice: `rename(path, renamedPath)`
2. Encountered token (`file`, type 'IDENT') that doesn't have a predefined statement parse function, so it's either an expression or an assignment statement
2. Did not encounter an assign (`=`) token, so this is an expression statement
2. Steps in parsing expression statement:

	a. Assigning token to the statement to track positioning [line: 13, col: 6]

	b. Parsing expression statements is extremely simple. Just parse the expression and wrap it within a Statement implementation...

	c. Successfully parsed the expression statement: `write(renamedPath, 

This is a new string)`

	d. Successfully parsed the entire expression statement: `write(renamedPath, 

This is a new string)`
2. Parsed a statement to append to program's `Statements` slice: `write(renamedPath, 

This is a new string)`
2. Encountered token (`io`, type 'IDENT') that doesn't have a predefined statement parse function, so it's either an expression or an assignment statement
2. Did not encounter an assign (`=`) token, so this is an expression statement
2. Steps in parsing expression statement:

	a. Assigning token to the statement to track positioning [line: 15, col: 4]

	b. Parsing expression statements is extremely simple. Just parse the expression and wrap it within a Statement implementation...

	c. Successfully parsed the expression statement: `println(file.isdir(renamedPath))`

	d. Successfully parsed the entire expression statement: `println(file.isdir(renamedPath))`
2. Parsed a statement to append to program's `Statements` slice: `println(file.isdir(renamedPath))`
2. Encountered token (`io`, type 'IDENT') that doesn't have a predefined statement parse function, so it's either an expression or an assignment statement
2. Did not encounter an assign (`=`) token, so this is an expression statement
2. Steps in parsing expression statement:

	a. Assigning token to the statement to track positioning [line: 16, col: 4]

	b. Parsing expression statements is extremely simple. Just parse the expression and wrap it within a Statement implementation...

	c. Successfully parsed the expression statement: `println(file.isfile(renamedPath))`

	d. Successfully parsed the entire expression statement: `println(file.isfile(renamedPath))`
2. Parsed a statement to append to program's `Statements` slice: `println(file.isfile(renamedPath))`
2. Encountered token (`io`, type 'IDENT') that doesn't have a predefined statement parse function, so it's either an expression or an assignment statement
2. Did not encounter an assign (`=`) token, so this is an expression statement
2. Steps in parsing expression statement:

	a. Assigning token to the statement to track positioning [line: 18, col: 4]

	b. Parsing expression statements is extremely simple. Just parse the expression and wrap it within a Statement implementation...

	c. Successfully parsed the expression statement: `println(file.exists(renamedPath))`

	d. Successfully parsed the entire expression statement: `println(file.exists(renamedPath))`
2. Parsed a statement to append to program's `Statements` slice: `println(file.exists(renamedPath))`
2. Encountered token (`io`, type 'IDENT') that doesn't have a predefined statement parse function, so it's either an expression or an assignment statement
2. Did not encounter an assign (`=`) token, so this is an expression statement
2. Steps in parsing expression statement:

	a. Assigning token to the statement to track positioning [line: 19, col: 4]

	b. Parsing expression statements is extremely simple. Just parse the expression and wrap it within a Statement implementation...

	c. Successfully parsed the expression statement: `println(file.exists(../thisdoesnotexits))`

	d. Successfully parsed the entire expression statement: `println(file.exists(../thisdoesnotexits))`
2. Parsed a statement to append to program's `Statements` slice: `println(file.exists(../thisdoesnotexits))`
2. Encountered a `RETURN` token, calling `parseReturnStatement()`...
2. Steps in parsing return statement:

	a. Assigning token to the statement to track positioning [line: 21, col: 1]

	b. Parsing the expression to return...

	c. Successfully parsed a valid expression to return: `(Project written to  + strings.concat(', path, '))`

	d. Successfully parsed the entire return statement: `return (Project written to  + strings.concat(', path, '));`
2. Parsed a statement to append to program's `Statements` slice: `return (Project written to  + strings.concat(', path, '));`


**Successfully parsed the program!**

Here is your program node in tree format:
```
{
  "NoStatements": false,
  "statements": [
    {
      "Token": {
        "Type": "LET",
        "Literal": "let",
        "Line": 5,
        "Col": 1
      },
      "name": {
        "Token": {
          "Type": "IDENT",
          "Literal": "path",
          "Line": 5,
          "Col": 5
        },
        "value": "path"
      },
      "value": {
        "Token": {
          "Type": "STRING",
          "Literal": "./test.clr",
          "Line": 0,
          "Col": 0
        },
        "value": "./test.clr"
      }
    },
    {
      "Token": {
        "Type": "IDENT",
        "Literal": "create",
        "Line": 6,
        "Col": 6
      },
      "expression": {
        "Token": {
          "Type": "(",
          "Literal": "(",
          "Line": 6,
          "Col": 12
        },
        "function": {
          "Token": {
            "Type": "IDENT",
            "Literal": "create",
            "Line": 6,
            "Col": 6
          },
          "value": "create"
        },
        "arguments": [
          {
            "Token": {
              "Type": "IDENT",
              "Literal": "path",
              "Line": 6,
              "Col": 13
            },
            "value": "path"
          }
        ]
      }
    },
    {
      "Token": {
        "Type": "IDENT",
        "Literal": "write",
        "Line": 7,
        "Col": 6
      },
      "expression": {
        "Token": {
          "Type": "(",
          "Literal": "(",
          "Line": 7,
          "Col": 11
        },
        "function": {
          "Token": {
            "Type": "IDENT",
            "Literal": "write",
            "Line": 7,
            "Col": 6
          },
          "value": "write"
        },
        "arguments": [
          {
            "Token": {
              "Type": "IDENT",
              "Literal": "path",
              "Line": 7,
              "Col": 12
            },
            "value": "path"
          },
          {
            "Token": {
              "Type": "STRING",
              "Literal": "myString",
              "Line": 0,
              "Col": 0
            },
            "value": "myString"
          }
        ]
      }
    },
    {
      "Token": {
        "Type": "LET",
        "Literal": "let",
        "Line": 9,
        "Col": 1
      },
      "name": {
        "Token": {
          "Type": "IDENT",
          "Literal": "renamedPath",
          "Line": 9,
          "Col": 5
        },
        "value": "renamedPath"
      },
      "value": {
        "Token": {
          "Type": "STRING",
          "Literal": "./test2.clr",
          "Line": 0,
          "Col": 0
        },
        "value": "./test2.clr"
      }
    },
    {
      "Token": {
        "Type": "IDENT",
        "Literal": "rename",
        "Line": 11,
        "Col": 6
      },
      "expression": {
        "Token": {
          "Type": "(",
          "Literal": "(",
          "Line": 11,
          "Col": 12
        },
        "function": {
          "Token": {
            "Type": "IDENT",
            "Literal": "rename",
            "Line": 11,
            "Col": 6
          },
          "value": "rename"
        },
        "arguments": [
          {
            "Token": {
              "Type": "IDENT",
              "Literal": "path",
              "Line": 11,
              "Col": 13
            },
            "value": "path"
          },
          {
            "Token": {
              "Type": "IDENT",
              "Literal": "renamedPath",
              "Line": 11,
              "Col": 19
            },
            "value": "renamedPath"
          }
        ]
      }
    },
    {
      "Token": {
        "Type": "IDENT",
        "Literal": "write",
        "Line": 13,
        "Col": 6
      },
      "expression": {
        "Token": {
          "Type": "(",
          "Literal": "(",
          "Line": 13,
          "Col": 11
        },
        "function": {
          "Token": {
            "Type": "IDENT",
            "Literal": "write",
            "Line": 13,
            "Col": 6
          },
          "value": "write"
        },
        "arguments": [
          {
            "Token": {
              "Type": "IDENT",
              "Literal": "renamedPath",
              "Line": 13,
              "Col": 12
            },
            "value": "renamedPath"
          },
          {
            "Token": {
              "Type": "STRING",
              "Literal": "\\n\\nThis is a new string",
              "Line": 0,
              "Col": 0
            },
            "value": "\n\nThis is a new string"
          }
        ]
      }
    },
    {
      "Token": {
        "Type": "IDENT",
        "Literal": "println",
        "Line": 15,
        "Col": 4
      },
      "expression": {
        "Token": {
          "Type": "(",
          "Literal": "(",
          "Line": 15,
          "Col": 11
        },
        "function": {
          "Token": {
            "Type": "IDENT",
            "Literal": "println",
            "Line": 15,
            "Col": 4
          },
          "value": "println"
        },
        "arguments": [
          {
            "Token": {
              "Type": "(",
              "Literal": "(",
              "Line": 15,
              "Col": 22
            },
            "function": {
              "Token": {
                "Type": "IDENT",
                "Literal": "isdir",
                "Line": 15,
                "Col": 17
              },
              "value": "file.isdir"
            },
            "arguments": [
              {
                "Token": {
                  "Type": "IDENT",
                  "Literal": "renamedPath",
                  "Line": 15,
                  "Col": 23
                },
                "value": "renamedPath"
              }
            ]
          }
        ]
      }
    },
    {
      "Token": {
        "Type": "IDENT",
        "Literal": "println",
        "Line": 16,
        "Col": 4
      },
      "expression": {
        "Token": {
          "Type": "(",
          "Literal": "(",
          "Line": 16,
          "Col": 11
        },
        "function": {
          "Token": {
            "Type": "IDENT",
            "Literal": "println",
            "Line": 16,
            "Col": 4
          },
          "value": "println"
        },
        "arguments": [
          {
            "Token": {
              "Type": "(",
              "Literal": "(",
              "Line": 16,
              "Col": 23
            },
            "function": {
              "Token": {
                "Type": "IDENT",
                "Literal": "isfile",
                "Line": 16,
                "Col": 17
              },
              "value": "file.isfile"
            },
            "arguments": [
              {
                "Token": {
                  "Type": "IDENT",
                  "Literal": "renamedPath",
                  "Line": 16,
                  "Col": 24
                },
                "value": "renamedPath"
              }
            ]
          }
        ]
      }
    },
    {
      "Token": {
        "Type": "IDENT",
        "Literal": "println",
        "Line": 18,
        "Col": 4
      },
      "expression": {
        "Token": {
          "Type": "(",
          "Literal": "(",
          "Line": 18,
          "Col": 11
        },
        "function": {
          "Token": {
            "Type": "IDENT",
            "Literal": "println",
            "Line": 18,
            "Col": 4
          },
          "value": "println"
        },
        "arguments": [
          {
            "Token": {
              "Type": "(",
              "Literal": "(",
              "Line": 18,
              "Col": 23
            },
            "function": {
              "Token": {
                "Type": "IDENT",
                "Literal": "exists",
                "Line": 18,
                "Col": 17
              },
              "value": "file.exists"
            },
            "arguments": [
              {
                "Token": {
                  "Type": "IDENT",
                  "Literal": "renamedPath",
                  "Line": 18,
                  "Col": 24
                },
                "value": "renamedPath"
              }
            ]
          }
        ]
      }
    },
    {
      "Token": {
        "Type": "IDENT",
        "Literal": "println",
        "Line": 19,
        "Col": 4
      },
      "expression": {
        "Token": {
          "Type": "(",
          "Literal": "(",
          "Line": 19,
          "Col": 11
        },
        "function": {
          "Token": {
            "Type": "IDENT",
            "Literal": "println",
            "Line": 19,
            "Col": 4
          },
          "value": "println"
        },
        "arguments": [
          {
            "Token": {
              "Type": "(",
              "Literal": "(",
              "Line": 19,
              "Col": 23
            },
            "function": {
              "Token": {
                "Type": "IDENT",
                "Literal": "exists",
                "Line": 19,
                "Col": 17
              },
              "value": "file.exists"
            },
            "arguments": [
              {
                "Token": {
                  "Type": "STRING",
                  "Literal": "../thisdoesnotexits",
                  "Line": 0,
                  "Col": 0
                },
                "value": "../thisdoesnotexits"
              }
            ]
          }
        ]
      }
    },
    {
      "Token": {
        "Type": "RETURN",
        "Literal": "return",
        "Line": 21,
        "Col": 1
      },
      "returnValue": {
        "Token": {
          "Type": "+",
          "Literal": "+",
          "Line": 21,
          "Col": 29
        },
        "left": {
          "Token": {
            "Type": "STRING",
            "Literal": "Project written to ",
            "Line": 0,
            "Col": 0
          },
          "value": "Project written to "
        },
        "operator": "+",
        "right": {
          "Token": {
            "Type": "(",
            "Literal": "(",
            "Line": 21,
            "Col": 44
          },
          "function": {
            "Token": {
              "Type": "IDENT",
              "Literal": "concat",
              "Line": 21,
              "Col": 38
            },
            "value": "strings.concat"
          },
          "arguments": [
            {
              "Token": {
                "Type": "STRING",
                "Literal": "'",
                "Line": 0,
                "Col": 0
              },
              "value": "'"
            },
            {
              "Token": {
                "Type": "IDENT",
                "Literal": "path",
                "Line": 21,
                "Col": 50
              },
              "value": "path"
            },
            {
              "Token": {
                "Type": "STRING",
                "Literal": "'",
                "Line": 0,
                "Col": 0
              },
              "value": "'"
            }
          ]
        }
      }
    }
  ],
  "modules": [
    {
      "Token": {
        "Type": "MOD",
        "Literal": "mod",
        "Line": 1,
        "Col": 1
      },
      "name": {
        "Token": {
          "Type": "IDENT",
          "Literal": "file",
          "Line": 1,
          "Col": 5
        },
        "value": "file"
      },
      "import_all": true,
      "imports": null
    },
    {
      "Token": {
        "Type": "MOD",
        "Literal": "mod",
        "Line": 2,
        "Col": 1
      },
      "name": {
        "Token": {
          "Type": "IDENT",
          "Literal": "strings",
          "Line": 2,
          "Col": 5
        },
        "value": "strings"
      },
      "import_all": false,
      "imports": [
        {
          "Token": {
            "Type": "IDENT",
            "Literal": "concat",
            "Line": 2,
            "Col": 16
          },
          "value": "concat"
        }
      ]
    },
    {
      "Token": {
        "Type": "MOD",
        "Literal": "mod",
        "Line": 3,
        "Col": 1
      },
      "name": {
        "Token": {
          "Type": "IDENT",
          "Literal": "io",
          "Line": 3,
          "Col": 5
        },
        "value": "io"
      },
      "import_all": false,
      "imports": [
        {
          "Token": {
            "Type": "IDENT",
            "Literal": "println",
            "Line": 3,
            "Col": 11
          },
          "value": "println"
        }
      ]
    }
  ]
}
```

## Evaluation
Evaluation is simply the traversing of the AST and executing its nodes accordingly.

The core of the evaluator is the Eval(node) function, which is called recursivly on the AST. Since the AST is a nicely formatted tree structure, it is pretty simple to traverse it recusively.

I would suggest inspecting the [evaluator](../../clear/evaluator/evaluator.go) and [object](../../clear/object/object.go) package to get a better understanding of how the evaluator works. It's very simple to understand due to its recursive nature.



